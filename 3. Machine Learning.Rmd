---
title: "Master's Thesis Code - Machine Learning"
author: "Ana Pérez"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## PREPARING THE DATA FOR PREDICTION

```{r}
sum_emp_isco <-merged_data_subset %>%
  group_by(YEAR, isco) %>%
  summarise(sum_isco = sum(totalemp, na.rm = TRUE)) 

sum_emp_year <- merged_data_subset %>%
  group_by(YEAR) %>%
  summarise(sum_year = sum(totalemp, na.rm = TRUE))

merged_totals <- sum_emp_isco%>%
  left_join(sum_emp_year, by = c("YEAR")) 

merged_totals <- merged_totals %>%
  mutate(share = (sum_isco / sum_year) * 100) |> dplyr::select(YEAR,isco,share)

merged_data_subset<- merged_data_subset%>%
  left_join(merged_totals, by = c("YEAR","isco")) 
```


```{r}
library(lme4)
library(lmerTest)
library(modelsummary) 
library(broom)
library(knitr)
```

### Distribution of target variable

This is the distribution of the outcome variable: 

```{r}
new_data %>% 
  ggplot(aes(x=iscoprop)) +
  geom_density(fill="navyblue") + theme_minimal()
```

### NA imputation

```{r}
new_data <- merged_data_subset |> 
  dplyr::select(-job,-sector,-occup, -totalemp,-empchange, -avg_change,-avg_year,-iscoprop) |> 
  distinct(.keep_all = TRUE)
  
sapply(new_data, function(x) sum(is.na(x))*100/nrow(new_data))
```

We have to make sure there are no NA'S in our data. For that purpose, and since the number of NA is very low, we are using the...imputations with the Random Forest algorithm from the mice function. 

```{r}
set.seed(123)
m = 5
mice_mod <- mice(new_data, m=m, method='rf')
new_data <- complete(mice_mod, action=m)
```

```{r}
training <- subset(new_data, YEAR >= 2012 & YEAR <= 2018) 
testing<- subset(new_data, YEAR ==2019) 
```

### Correlations

```{r}
cor_data <-training |> dplyr::select(-COUNTRY,-YEAR,-isco)
corr_change <- sort(cor(cor_data)["iscoprop",], decreasing = TRUE)
corr <- data.frame(Predictor = names(corr_change), Correlation = corr_change)
```

```{r}
nudge_x <- 0.01
my_col <- viridisLite::mako(4)[2]

corr %>% 
  ggplot(aes(y = reorder(Predictor, Correlation), x = Correlation)) +
  geom_point(col = my_col) +
  geom_segment(aes(xend = 0, yend = Predictor), col = my_col, size = 0.75) +
  geom_text(
    aes(x = 0, label = Predictor),
    size = 2.5,
    hjust = if_else(corr$Correlation > 0, 1, 0),
    nudge_x = if_else(corr$Correlation > 0, -nudge_x, nudge_x)
  ) +
  scale_y_discrete(breaks = NULL) +
  labs(title = "Correlations with the target variable",
       x = '', y = element_blank()) + theme_minimal()
```

### REGRESSION METHODS

#### Lambda coefficients

```{r}
set.seed(123)
lambda <- training |> dplyr::select(-isco,-YEAR,-COUNTRY) # remove non-numeric
X <- lambda |> select (-share)
Y <- lambda |> select (share)

grid = 10^seq(10, -2, length = 100)

lasso_data<-cv.glmnet(x=as.matrix(X), y=Y[,1], lambda=grid, alpha=1)
lambda_min<-predict(lasso_data, newx=as.matrix(X)[1:10,], s="lambda.min")
lasso_coeff <- as.data.frame(as.matrix(predict(lasso_data, type="coefficients", s="lambda.min"))) |>  mutate(across(c(lambda.min), round, 2))

coeff_df <- as.data.frame(as.matrix(lasso_coeff))
coeff_df$variable <- rownames(coeff_df)

# Filter non-zero coefficients and exclude intercept
selected_variables <- coeff_df %>%
  filter(lambda.min != 0) %>%
  pull(variable) %>%
  setdiff("(Intercept)")

print(selected_variables)
```

```{r}
all_variables <- c(selected_variables, "as.factor(COUNTRY)", "YEAR")
# Subset the original data to include only the selected variables
formula <- as.formula(paste("share ~ ", paste(all_variables, collapse = " + ")))
selected_data <- training %>% select(all_of(c("share", selected_variables, "COUNTRY","YEAR")))
formula
```


#### Ordinary Least Squares (OLS)

```{r}
set.seed(123)
# Fit a linear model
lm_model <- lm(formula, data = selected_data)
summary(lm_model)
```

```{r}
results <- tidy(lm_model)
```

#### Linear Mixed Models

```{r}
formula
```

```{r}
set.seed(123)
lmm_model <- lmer(share ~ sunratio + satratio + nightratio + shiftratio + extraratio + 
    supratio + ftratio + onratio + femratio + strength + dexterity + 
    navigation + uncodified + business + humanities + numeracy + 
    infogath + creativity + planning + social + serving + managing + 
    autonomy + latitude + control + team + repetitiv + standard + 
    certainty + machines + ICT + ICTbasic + ICTadvanced  + 
      (1 | COUNTRY) +  (1 | YEAR), data = training)

summary(lmm_model)
print(lmm_model,correlation=T)
```


```{r}
model3 <- lmer(share ~ sunratio + satratio + nightratio + shiftratio + extraratio + 
    supratio + ftratio + onratio + femratio + strength + dexterity + 
    navigation + uncodified + business + humanities + numeracy + 
    infogath + creativity + planning + social + serving + managing + 
    autonomy + latitude + control + team + repetitiv + standard + 
    certainty + machines + ICT + ICTbasic + ICTadvanced +
           (1 + sunratio + satratio + nightratio + shiftratio + extraratio + 
    supratio + ftratio + onratio + femratio| COUNTRY) + 
           (1 | YEAR), 
          control = lmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)), 
              data = training)
summary(model3)
```

### Evaluation and Robustness

From now on, we are going to try many models, so it’s convenient to create a data frame with all the predictors.

```{r}
test_results <- data.frame(share = testing$share)
```

```{r}
# Linear model 
test_results$lm <- predict(lm_model, newdata = testing, allow.new.levels = TRUE)
postResample(pred = test_results$lm,  obs = test_results$share)

# Linear Mixed Model (COUNTRY)
test_results$lmm <- predict(lmm_model, newdata = testing, allow.new.levels = TRUE)
postResample(pred = test_results$lmm,  obs = test_results$share)

# Linear Mixed Model (COUNTRY, YEAR,ISCO)
test_results$lmm2 <- predict(model3, newdata = testing, allow.new.levels = TRUE)
postResample(pred = test_results$lmm2,  obs = test_results$share)
```

```{r}
qplot(test_results$lmm2, test_results$share) + 
  labs(title="Linear Regression Observed VS Predicted",
       x="Predicted", y="Observed") +
  lims(x = c(0,20), y = c(0,20)) +
  geom_abline(intercept = 0, slope = 1, colour = "darkred") +
  theme_bw()
```

```{r}
lm_coef <- varImp(lm_model, scale = FALSE)
```

Extracting the proportion of variance due to COUNTRY/YEAR random effects

```{r}
# Extract variance components
var_components <- VarCorr(model3)
print(var_components)

# Extract random effect variance for COUNTRY
random_effect_variance <- unlist(var_components$YEAR)[1] 
# Total variance (residual + random effect variance)
total_variance <- attr(VarCorr(model3), "sc")^2

# Proportion of variance due to random effect (COUNTRY)
prop_variance_random <- random_effect_variance / total_variance
prop_variance_random
```


```{r}
coefs <- summary(model3)$coefficients

coefs_df <- data.frame(Variable = rownames(coefs), Estimate = coefs[, 1], CI_low = coefs[, 1] - 1.96 * coefs[, 2], CI_high = coefs[, 1] + 1.96 * coefs[, 2])

ggplot(coefs_df, aes(x = reorder(Variable, Estimate), y = Estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_low, ymax = CI_high), width = 0.2) +
  coord_flip() +
  theme_minimal() 
```


```{r}
anova(lmm_model, model3)
```
Con base en la comparación de los criterios de información y la prueba de Chi-cuadrado, model3 es claramente un modelo superior en comparación con lmm_model. Esto significa que la inclusión de efectos aleatorios adicionales (para sunratio, satratio, isco y YEAR) mejora significativamente el ajuste del modelo a tus datos

Let’s summarize the MAE for all the tools to select the best models in predicting our response variable:

```{r}
diff_rounded <- apply(test_results[-1], 2, function(x) round(mean(abs(x - test_results$share)), digits = 8))
diff_rounded
```

```{r}
# Combination
test_results$pred_change = (test_results$lm + test_results$lmm2)/2
postResample(pred = test_results$pred_change,  obs = test_results$iscoprop)
```

```{r}
yhat = test_results$pred_change
hist(yhat, col="lightblue")
```

**Comparison of real vs predicted average change in employment levels across occupations**

```{r}
real_change <- test_results %>% ggplot(aes(x=iscoprop)) + 
  geom_density(fill="navyblue") + xlim(0, 20)
pred_change<- test_results |> ggplot(aes(x=pred_change)) + 
  geom_density(fill="navyblue") +  xlim(0, 20)

# Arrange together
ggarrange(real_change,pred_change,
          ncol =2, nrow=1) 
```
```{r}
library(sjPlot)
plot_model(model3, type = "pred")

fixed_effects <- fixef(model3)
importance <- abs(fixed_effects[-1])  # Exclude the intercept
importance_df <- data.frame(Variable = names(importance), Importance = importance)
importance_df <- importance_df %>% arrange(desc(Importance))

plot <- plot_model(model3, type = "est", show.values = TRUE, value.offset = .3) +
  labs(title = "Fixed Effects - model3") + theme_minimal()


plot <- plot +
  scale_x_discrete(limits = importance_df$Variable) +
  labs(title = "Fixed Effects - Linear Mixed Model")

print(plot)
```



